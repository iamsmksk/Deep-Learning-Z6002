{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define evaluate_model function\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "    return accuracy, report, confusion\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Generate a balanced training dataset with 10 classes and 10,000 total images\n",
        "balanced_x_train = []\n",
        "balanced_y_train = []\n",
        "num_images_per_class = 1000\n",
        "\n",
        "for class_label in range(10):\n",
        "    indices = np.where(y_train == class_label)[0]\n",
        "    np.random.shuffle(indices)\n",
        "    selected_indices = indices[:num_images_per_class]\n",
        "    balanced_x_train.extend(x_train[selected_indices])\n",
        "    balanced_y_train.extend(y_train[selected_indices])\n",
        "\n",
        "balanced_x_train = np.array(balanced_x_train)\n",
        "balanced_y_train = np.array(balanced_y_train)\n",
        "\n",
        "# Flatten images and scale pixel values to the range [0, 1]\n",
        "balanced_x_train_flat = balanced_x_train.reshape(balanced_x_train.shape[0], -1) / 255.0\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "# Convert images to grayscale\n",
        "balanced_x_train_gray = np.mean(balanced_x_train, axis=3, keepdims=True) / 255.0\n",
        "x_test_gray = np.mean(x_test, axis=3, keepdims=True) / 255.0\n",
        "\n",
        "# Initialize classifiers\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "random_forest_clf = RandomForestClassifier()\n",
        "logistic_regression_clf = LogisticRegression(max_iter=1000)\n",
        "svm_clf = SVC()\n",
        "\n",
        "# Train and evaluate models for color images\n",
        "print(\"Color Images:\")\n",
        "print(\"==========================\")\n",
        "# Train Decision Tree\n",
        "decision_tree_clf.fit(balanced_x_train_flat, balanced_y_train)\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy, dt_report, dt_confusion = evaluate_model(decision_tree_clf, x_test_flat, y_test)\n",
        "\n",
        "# Train Random Forest\n",
        "random_forest_clf.fit(balanced_x_train_flat, balanced_y_train)\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy, rf_report, rf_confusion = evaluate_model(random_forest_clf, x_test_flat, y_test)\n",
        "\n",
        "# Train Logistic Regression\n",
        "logistic_regression_clf.fit(balanced_x_train_flat, balanced_y_train)\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy, lr_report, lr_confusion = evaluate_model(logistic_regression_clf, x_test_flat, y_test)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler = StandardScaler()\n",
        "balanced_x_train_scaled = scaler.fit_transform(balanced_x_train_flat)\n",
        "x_test_scaled = scaler.transform(x_test_flat)\n",
        "\n",
        "# Train SVM\n",
        "svm_clf.fit(balanced_x_train_scaled, balanced_y_train)\n",
        "# Evaluate SVM\n",
        "svm_accuracy, svm_report, svm_confusion = evaluate_model(svm_clf, x_test_scaled, y_test)\n",
        "\n",
        "# Print results for color images\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
        "print(\"Decision Tree Classification Report:\\n\", dt_report)\n",
        "print(\"Decision Tree Confusion Matrix:\\n\", dt_confusion)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\\n\", rf_report)\n",
        "print(\"Random Forest Confusion Matrix:\\n\", rf_confusion)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
        "print(\"Logistic Regression Classification Report:\\n\", lr_report)\n",
        "print(\"Logistic Regression Confusion Matrix:\\n\", lr_confusion)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Classification Report:\\n\", svm_report)\n",
        "print(\"SVM Confusion Matrix:\\n\", svm_confusion)\n",
        "\n",
        "# Train and evaluate models for grayscale images\n",
        "print(\"\\nGrayscale Images:\")\n",
        "print(\"==========================\")\n",
        "# Train Decision Tree\n",
        "decision_tree_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), balanced_y_train)\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy_gray, dt_report_gray, dt_confusion_gray = evaluate_model(decision_tree_clf, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "\n",
        "# Train Random Forest\n",
        "random_forest_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), balanced_y_train)\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy_gray, rf_report_gray, rf_confusion_gray = evaluate_model(random_forest_clf, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "\n",
        "# Train Logistic Regression\n",
        "logistic_regression_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), balanced_y_train)\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy_gray, lr_report_gray, lr_confusion_gray = evaluate_model(logistic_regression_clf, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler_gray = StandardScaler()\n",
        "balanced_x_train_gray_scaled = scaler_gray.fit_transform(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1))\n",
        "x_test_gray_scaled = scaler_gray.transform(x_test_gray.reshape(x_test_gray.shape[0], -1))\n",
        "\n",
        "# Train SVM\n",
        "svm_clf.fit(balanced_x_train_gray_scaled, balanced_y_train)\n",
        "# Evaluate SVM\n",
        "svm_accuracy_gray, svm_report_gray, svm_confusion_gray = evaluate_model(svm_clf, x_test_gray_scaled, y_test)\n",
        "\n",
        "# Print results for grayscale images\n",
        "print(\"Decision Tree Accuracy (Grayscale):\", dt_accuracy_gray)\n",
        "print(\"Decision Tree Classification Report (Grayscale):\\n\", dt_report_gray)\n",
        "print(\"Decision Tree Confusion Matrix (Grayscale):\\n\", dt_confusion_gray)\n",
        "\n",
        "print(\"Random Forest Accuracy (Grayscale):\", rf_accuracy_gray)\n",
        "print(\"Random Forest Classification Report (Grayscale):\\n\", rf_report_gray)\n",
        "print(\"Random Forest Confusion Matrix (Grayscale):\\n\", rf_confusion_gray)\n",
        "\n",
        "print(\"Logistic Regression Accuracy (Grayscale):\", lr_accuracy_gray)\n",
        "print(\"Logistic Regression Classification Report (Grayscale):\\n\", lr_report_gray)\n",
        "print(\"Logistic Regression Confusion Matrix (Grayscale):\\n\", lr_confusion_gray)\n",
        "\n",
        "print(\"SVM Accuracy (Grayscale):\", svm_accuracy_gray)\n",
        "print(\"SVM Classification Report (Grayscale):\\n\", svm_report_gray)\n",
        "print(\"SVM Confusion Matrix (Grayscale):\\n\", svm_confusion_gray)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUIuFvzDwuvM",
        "outputId": "414e599b-4aa9-4134-b8f2-e59f1ebcf4bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Color Images:\n",
            "==========================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-fabf07969f90>:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_clf.fit(balanced_x_train_flat, balanced_y_train)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.24\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.33      0.32      1000\n",
            "           1       0.25      0.22      0.23      1000\n",
            "           2       0.18      0.20      0.19      1000\n",
            "           3       0.16      0.15      0.15      1000\n",
            "           4       0.20      0.22      0.21      1000\n",
            "           5       0.22      0.20      0.21      1000\n",
            "           6       0.25      0.25      0.25      1000\n",
            "           7       0.23      0.23      0.23      1000\n",
            "           8       0.33      0.36      0.35      1000\n",
            "           9       0.25      0.24      0.25      1000\n",
            "\n",
            "    accuracy                           0.24     10000\n",
            "   macro avg       0.24      0.24      0.24     10000\n",
            "weighted avg       0.24      0.24      0.24     10000\n",
            "\n",
            "Decision Tree Confusion Matrix:\n",
            " [[328  67  92  51  67  48  42  64 161  80]\n",
            " [ 87 221  66  74  54  59  77  77 123 162]\n",
            " [101  56 196  89 157  87 115  97  66  36]\n",
            " [ 69  69 105 151 109 147 113 105  54  78]\n",
            " [ 59  47 171  90 224  92 134  97  38  48]\n",
            " [ 53  58  97 139 123 201  96 101  63  69]\n",
            " [ 46  62 112 122 155  83 253  80  39  48]\n",
            " [ 57  66 101  99 118 100  85 226  51  97]\n",
            " [141  84  61  67  55  43  41  57 358  93]\n",
            " [ 89 153  64  81  51  64  56  78 122 242]]\n",
            "Random Forest Accuracy: 0.4249\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.54      0.52      1000\n",
            "           1       0.48      0.48      0.48      1000\n",
            "           2       0.33      0.28      0.30      1000\n",
            "           3       0.30      0.25      0.27      1000\n",
            "           4       0.36      0.37      0.37      1000\n",
            "           5       0.38      0.37      0.38      1000\n",
            "           6       0.43      0.49      0.46      1000\n",
            "           7       0.44      0.39      0.41      1000\n",
            "           8       0.54      0.58      0.56      1000\n",
            "           9       0.43      0.51      0.47      1000\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.42      0.42      0.42     10000\n",
            "weighted avg       0.42      0.42      0.42     10000\n",
            "\n",
            "Random Forest Confusion Matrix:\n",
            " [[536  34  57  25  28  24  27  29 181  59]\n",
            " [ 36 476  21  39  28  41  52  38  73 196]\n",
            " [116  44 284  77 156  71 126  57  34  35]\n",
            " [ 62  41  76 246  96 182 129  73  25  70]\n",
            " [ 53  23 155  56 374  65 137  85  25  27]\n",
            " [ 39  35  89 150  78 374  75  89  30  41]\n",
            " [ 18  30  92  79 138  64 486  39   9  45]\n",
            " [ 48  45  61  74 107  93  52 386  29 105]\n",
            " [109  80  15  36  19  43  13  21 582  82]\n",
            " [ 55 175  16  33  20  27  29  54  86 505]]\n",
            "Logistic Regression Accuracy: 0.3275\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.42      0.41      1000\n",
            "           1       0.38      0.36      0.37      1000\n",
            "           2       0.25      0.25      0.25      1000\n",
            "           3       0.22      0.21      0.22      1000\n",
            "           4       0.27      0.27      0.27      1000\n",
            "           5       0.25      0.25      0.25      1000\n",
            "           6       0.35      0.34      0.35      1000\n",
            "           7       0.34      0.32      0.33      1000\n",
            "           8       0.43      0.49      0.46      1000\n",
            "           9       0.37      0.36      0.36      1000\n",
            "\n",
            "    accuracy                           0.33     10000\n",
            "   macro avg       0.33      0.33      0.33     10000\n",
            "weighted avg       0.33      0.33      0.33     10000\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[419  53  71  47  37  42  25  62 189  55]\n",
            " [ 64 360  36  58  39  51  59  54 105 174]\n",
            " [ 99  36 246 109 147  97 100  83  54  29]\n",
            " [ 52  59 118 213  83 178 110  80  49  58]\n",
            " [ 50  30 157  77 273 109 132 104  33  35]\n",
            " [ 48  50 117 159 114 253  87  89  43  40]\n",
            " [ 26  38  87 138 136 112 342  58  22  41]\n",
            " [ 46  55  80  88 122  99  46 324  58  82]\n",
            " [166  74  28  40  21  42  18  26 489  96]\n",
            " [ 83 195  32  35  40  29  54  69 107 356]]\n",
            "SVM Accuracy: 0.4752\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.54      0.54      1000\n",
            "           1       0.57      0.56      0.56      1000\n",
            "           2       0.37      0.32      0.34      1000\n",
            "           3       0.34      0.34      0.34      1000\n",
            "           4       0.41      0.41      0.41      1000\n",
            "           5       0.43      0.39      0.41      1000\n",
            "           6       0.48      0.59      0.53      1000\n",
            "           7       0.54      0.44      0.48      1000\n",
            "           8       0.57      0.63      0.60      1000\n",
            "           9       0.50      0.55      0.53      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.47      0.48      0.47     10000\n",
            "weighted avg       0.47      0.48      0.47     10000\n",
            "\n",
            "SVM Confusion Matrix:\n",
            " [[541  42  63  20  29  23  26  27 165  64]\n",
            " [ 30 555  22  48  14  23  24  29  67 188]\n",
            " [102  28 322 106 148  51 130  59  31  23]\n",
            " [ 49  33  75 335  67 184 122  46  26  63]\n",
            " [ 57  16 154  56 406  50 149  65  28  19]\n",
            " [ 28  20  84 182  73 387 101  64  34  27]\n",
            " [ 16  23  76  89 108  52 586  17  12  21]\n",
            " [ 44  31  54  83 113  83  54 437  24  77]\n",
            " [101  73  19  35  17  21  12  22 629  71]\n",
            " [ 41 159  13  46  16  20  27  37  87 554]]\n",
            "\n",
            "Grayscale Images:\n",
            "==========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-fabf07969f90>:104: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), balanced_y_train)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy (Grayscale): 0.205\n",
            "Decision Tree Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.25      0.24      1000\n",
            "           1       0.23      0.21      0.22      1000\n",
            "           2       0.17      0.18      0.18      1000\n",
            "           3       0.15      0.14      0.15      1000\n",
            "           4       0.17      0.17      0.17      1000\n",
            "           5       0.18      0.18      0.18      1000\n",
            "           6       0.19      0.19      0.19      1000\n",
            "           7       0.18      0.19      0.18      1000\n",
            "           8       0.26      0.27      0.26      1000\n",
            "           9       0.28      0.25      0.26      1000\n",
            "\n",
            "    accuracy                           0.20     10000\n",
            "   macro avg       0.21      0.20      0.21     10000\n",
            "weighted avg       0.21      0.20      0.21     10000\n",
            "\n",
            "Decision Tree Confusion Matrix (Grayscale):\n",
            " [[252  59 106  60  74  75  79  83 140  72]\n",
            " [ 90 214  56  78  64  83  82  73 127 133]\n",
            " [135  62 182  89 141  90 101 107  52  41]\n",
            " [ 77  71  91 145 105 159 116  98  77  61]\n",
            " [ 80  63 139 103 174 104 132 104  65  36]\n",
            " [ 65  51 115 142  98 184  87 136  63  59]\n",
            " [ 84  94 130 105 109  95 189  75  64  55]\n",
            " [ 76  64  97 106 113  88  96 187  85  88]\n",
            " [130  95  79  49  62  84  45  80 271 105]\n",
            " [ 83 141  61  80  61  54  64 101 103 252]]\n",
            "Random Forest Accuracy (Grayscale): 0.3731\n",
            "Random Forest Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.42      0.41      1000\n",
            "           1       0.44      0.41      0.42      1000\n",
            "           2       0.32      0.30      0.31      1000\n",
            "           3       0.28      0.21      0.24      1000\n",
            "           4       0.29      0.33      0.31      1000\n",
            "           5       0.37      0.35      0.36      1000\n",
            "           6       0.37      0.40      0.38      1000\n",
            "           7       0.38      0.32      0.35      1000\n",
            "           8       0.45      0.50      0.47      1000\n",
            "           9       0.41      0.49      0.45      1000\n",
            "\n",
            "    accuracy                           0.37     10000\n",
            "   macro avg       0.37      0.37      0.37     10000\n",
            "weighted avg       0.37      0.37      0.37     10000\n",
            "\n",
            "Random Forest Confusion Matrix (Grayscale):\n",
            " [[421  39 100  29  69  22  50  42 179  49]\n",
            " [ 35 411  16  42  46  48  81  43  83 195]\n",
            " [105  42 302  69 152  62 128  60  47  33]\n",
            " [ 79  44  73 209 114 168 115  73  39  86]\n",
            " [ 70  34 166  55 328  59 125  91  42  30]\n",
            " [ 71  35  81 130  84 354  69  93  40  43]\n",
            " [ 48  57  91  80 139  74 395  34  25  57]\n",
            " [ 68  57  65  65 118  97  44 320  57 109]\n",
            " [106  67  33  44  34  48  25  36 499 108]\n",
            " [ 59 149  28  29  29  26  40  47 101 492]]\n",
            "Logistic Regression Accuracy (Grayscale): 0.2455\n",
            "Logistic Regression Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.31      0.30      1000\n",
            "           1       0.28      0.28      0.28      1000\n",
            "           2       0.20      0.17      0.18      1000\n",
            "           3       0.17      0.15      0.16      1000\n",
            "           4       0.18      0.18      0.18      1000\n",
            "           5       0.23      0.24      0.24      1000\n",
            "           6       0.22      0.21      0.21      1000\n",
            "           7       0.21      0.20      0.21      1000\n",
            "           8       0.31      0.35      0.33      1000\n",
            "           9       0.33      0.36      0.34      1000\n",
            "\n",
            "    accuracy                           0.25     10000\n",
            "   macro avg       0.24      0.25      0.24     10000\n",
            "weighted avg       0.24      0.25      0.24     10000\n",
            "\n",
            "Logistic Regression Confusion Matrix (Grayscale):\n",
            " [[311  50 102  63  65  74  34  74 156  71]\n",
            " [ 52 281  34  54  61  42 104  61 118 193]\n",
            " [118  52 172 112 146 104 115  91  59  31]\n",
            " [ 70  71  91 146 105 163 110 107  69  68]\n",
            " [ 61  43 126 103 181 121 138 122  54  51]\n",
            " [ 80  45 103 101 120 243  96  92  82  38]\n",
            " [ 66 113  68 104 134 104 210  78  45  78]\n",
            " [ 72  61  99  82 119 103  71 202 100  91]\n",
            " [154  92  54  52  25  67  37  49 353 117]\n",
            " [ 69 189  21  40  45  31  53  77 119 356]]\n",
            "SVM Accuracy (Grayscale): 0.401\n",
            "SVM Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.36      0.39      1000\n",
            "           1       0.49      0.47      0.48      1000\n",
            "           2       0.32      0.28      0.29      1000\n",
            "           3       0.29      0.25      0.27      1000\n",
            "           4       0.33      0.41      0.37      1000\n",
            "           5       0.42      0.34      0.38      1000\n",
            "           6       0.39      0.47      0.43      1000\n",
            "           7       0.45      0.36      0.40      1000\n",
            "           8       0.45      0.56      0.50      1000\n",
            "           9       0.45      0.50      0.48      1000\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.40      0.40      0.40     10000\n",
            "weighted avg       0.40      0.40      0.40     10000\n",
            "\n",
            "SVM Confusion Matrix (Grayscale):\n",
            " [[364  44 101  29 101  26  51  37 188  59]\n",
            " [ 26 467  17  42  37  17  72  33 101 188]\n",
            " [ 92  26 276  97 181  49 151  53  44  31]\n",
            " [ 66  48  71 250 102 153 136  69  43  62]\n",
            " [ 52  31 133  43 414  45 139  72  53  18]\n",
            " [ 54  27  95 164  98 339  79  66  43  35]\n",
            " [ 39  50  74  81 136  53 474  23  26  44]\n",
            " [ 56  40  57  81 127  70  53 364  64  88]\n",
            " [ 78  72  35  46  33  35  22  42 564  73]\n",
            " [ 34 153  16  38  28  21  51  44 117 498]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define evaluate_model function\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "    return accuracy, report, confusion\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Generate a balanced training dataset with 10 classes and 10,000 total images\n",
        "balanced_x_train = []\n",
        "balanced_y_train = []\n",
        "num_images_per_class = 1000\n",
        "\n",
        "for class_label in range(10):\n",
        "    indices = np.where(y_train == class_label)[0]\n",
        "    np.random.shuffle(indices)\n",
        "    selected_indices = indices[:num_images_per_class]\n",
        "    balanced_x_train.extend(x_train[selected_indices])\n",
        "    balanced_y_train.extend(y_train[selected_indices])\n",
        "\n",
        "balanced_x_train = np.array(balanced_x_train)\n",
        "balanced_y_train = np.array(balanced_y_train)\n",
        "\n",
        "# Split training data into 80% training and 20% validation\n",
        "x_train_balanced, x_val_balanced, y_train_balanced, y_val_balanced = train_test_split(balanced_x_train, balanced_y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Flatten images and scale pixel values to the range [0, 1]\n",
        "balanced_x_train_flat = x_train_balanced.reshape(x_train_balanced.shape[0], -1) / 255.0\n",
        "x_val_flat = x_val_balanced.reshape(x_val_balanced.shape[0], -1) / 255.0\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "# Convert images to grayscale\n",
        "balanced_x_train_gray = np.mean(x_train_balanced, axis=3, keepdims=True) / 255.0\n",
        "x_val_gray = np.mean(x_val_balanced, axis=3, keepdims=True) / 255.0\n",
        "x_test_gray = np.mean(x_test, axis=3, keepdims=True) / 255.0\n",
        "\n",
        "# Initialize classifiers\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "random_forest_clf = RandomForestClassifier()\n",
        "logistic_regression_clf = LogisticRegression(max_iter=1000)\n",
        "svm_clf = SVC()\n",
        "\n",
        "# Train and evaluate models for color images\n",
        "print(\"Color Images (20% Validation of Training Dataset):\")\n",
        "print(\"==========================\")\n",
        "# Train Decision Tree\n",
        "decision_tree_clf.fit(balanced_x_train_flat, y_train_balanced)\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy, dt_report, dt_confusion = evaluate_model(decision_tree_clf, x_val_flat, y_val_balanced)\n",
        "\n",
        "# Train Random Forest\n",
        "random_forest_clf.fit(balanced_x_train_flat, y_train_balanced)\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy, rf_report, rf_confusion = evaluate_model(random_forest_clf, x_val_flat, y_val_balanced)\n",
        "\n",
        "# Train Logistic Regression\n",
        "logistic_regression_clf.fit(balanced_x_train_flat, y_train_balanced)\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy, lr_report, lr_confusion = evaluate_model(logistic_regression_clf, x_val_flat, y_val_balanced)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler = StandardScaler()\n",
        "balanced_x_train_scaled = scaler.fit_transform(balanced_x_train_flat)\n",
        "x_val_scaled = scaler.transform(x_val_flat)\n",
        "x_test_scaled = scaler.transform(x_test_flat)\n",
        "\n",
        "# Train SVM\n",
        "svm_clf.fit(balanced_x_train_scaled, y_train_balanced)\n",
        "# Evaluate SVM\n",
        "svm_accuracy, svm_report, svm_confusion = evaluate_model(svm_clf, x_val_scaled, y_val_balanced)\n",
        "\n",
        "# Print results for color images\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
        "print(\"Decision Tree Classification Report:\\n\", dt_report)\n",
        "print(\"Decision Tree Confusion Matrix:\\n\", dt_confusion)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\\n\", rf_report)\n",
        "print(\"Random Forest Confusion Matrix:\\n\", rf_confusion)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
        "print(\"Logistic Regression Classification Report:\\n\", lr_report)\n",
        "print(\"Logistic Regression Confusion Matrix:\\n\", lr_confusion)\n",
        "\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Classification Report:\\n\", svm_report)\n",
        "print(\"SVM Confusion Matrix:\\n\", svm_confusion)\n",
        "\n",
        "# Train and evaluate models for grayscale images\n",
        "print(\"\\nGrayscale Images (20% Validation of Training Dataset):\")\n",
        "print(\"==========================\")\n",
        "# Train Decision Tree\n",
        "decision_tree_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), y_train_balanced)\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy_gray, dt_report_gray, dt_confusion_gray = evaluate_model(decision_tree_clf, x_val_gray.reshape(x_val_gray.shape[0], -1), y_val_balanced)\n",
        "\n",
        "# Train Random Forest\n",
        "random_forest_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), y_train_balanced)\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy_gray, rf_report_gray, rf_confusion_gray = evaluate_model(random_forest_clf, x_val_gray.reshape(x_val_gray.shape[0], -1), y_val_balanced)\n",
        "\n",
        "# Train Logistic Regression\n",
        "logistic_regression_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), y_train_balanced)\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy_gray, lr_report_gray, lr_confusion_gray = evaluate_model(logistic_regression_clf, x_val_gray.reshape(x_val_gray.shape[0], -1), y_val_balanced)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler_gray = StandardScaler()\n",
        "balanced_x_train_gray_scaled = scaler_gray.fit_transform(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1))\n",
        "x_val_gray_scaled = scaler_gray.transform(x_val_gray.reshape(x_val_gray.shape[0], -1))\n",
        "x_test_gray_scaled = scaler_gray.transform(x_test_gray.reshape(x_test_gray.shape[0], -1))\n",
        "\n",
        "# Train SVM\n",
        "svm_clf.fit(balanced_x_train_gray_scaled, y_train_balanced)\n",
        "# Evaluate SVM\n",
        "svm_accuracy_gray, svm_report_gray, svm_confusion_gray = evaluate_model(svm_clf, x_val_gray_scaled, y_val_balanced)\n",
        "\n",
        "# Print results for grayscale images\n",
        "print(\"Decision Tree Accuracy (Grayscale):\", dt_accuracy_gray)\n",
        "print(\"Decision Tree Classification Report (Grayscale):\\n\", dt_report_gray)\n",
        "print(\"Decision Tree Confusion Matrix (Grayscale):\\n\", dt_confusion_gray)\n",
        "\n",
        "print(\"Random Forest Accuracy (Grayscale):\", rf_accuracy_gray)\n",
        "print(\"Random Forest Classification Report (Grayscale):\\n\", rf_report_gray)\n",
        "print(\"Random Forest Confusion Matrix (Grayscale):\\n\", rf_confusion_gray)\n",
        "\n",
        "print(\"Logistic Regression Accuracy (Grayscale):\", lr_accuracy_gray)\n",
        "print(\"Logistic Regression Classification Report (Grayscale):\\n\", lr_report_gray)\n",
        "print(\"Logistic Regression Confusion Matrix (Grayscale):\\n\", lr_confusion_gray)\n",
        "\n",
        "print(\"SVM Accuracy (Grayscale):\", svm_accuracy_gray)\n",
        "print(\"SVM Classification Report (Grayscale):\\n\", svm_report_gray)\n",
        "print(\"SVM Confusion Matrix (Grayscale):\\n\", svm_confusion_gray)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxyWzUU9Ca-1",
        "outputId": "16178efe-ed25-44f0-e350-b3299925d283"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color Images (20% Validation of Training Dataset):\n",
            "==========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-64d5acfcf5d1>:65: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_clf.fit(balanced_x_train_flat, y_train_balanced)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.231\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.30      0.30       208\n",
            "           1       0.24      0.21      0.22       202\n",
            "           2       0.16      0.21      0.19       192\n",
            "           3       0.14      0.13      0.14       201\n",
            "           4       0.19      0.18      0.18       209\n",
            "           5       0.20      0.18      0.19       186\n",
            "           6       0.23      0.23      0.23       211\n",
            "           7       0.23      0.20      0.21       204\n",
            "           8       0.35      0.34      0.35       212\n",
            "           9       0.28      0.31      0.30       175\n",
            "\n",
            "    accuracy                           0.23      2000\n",
            "   macro avg       0.23      0.23      0.23      2000\n",
            "weighted avg       0.23      0.23      0.23      2000\n",
            "\n",
            "Decision Tree Confusion Matrix:\n",
            " [[63 18 24  9 14 10  5 11 29 25]\n",
            " [17 43 15 14 12 12 19 12 25 33]\n",
            " [23  8 41 26 25 13 24 14 14  4]\n",
            " [13 20 22 27 26 23 24 23 10 13]\n",
            " [15  7 37 26 37 15 34 23  9  6]\n",
            " [10 17 16 33 18 34 23 14 10 11]\n",
            " [12  7 37 23 20 21 49 20 11 11]\n",
            " [19 12 25 16 28 16 21 40  8 19]\n",
            " [28 29 15 13  9 11  9  9 73 16]\n",
            " [13 21 17 12  8 15  7  9 18 55]]\n",
            "Random Forest Accuracy: 0.3955\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.47      0.47       208\n",
            "           1       0.46      0.49      0.47       202\n",
            "           2       0.33      0.31      0.32       192\n",
            "           3       0.28      0.20      0.23       201\n",
            "           4       0.32      0.38      0.35       209\n",
            "           5       0.35      0.33      0.34       186\n",
            "           6       0.37      0.39      0.38       211\n",
            "           7       0.47      0.35      0.40       204\n",
            "           8       0.52      0.55      0.53       212\n",
            "           9       0.37      0.48      0.42       175\n",
            "\n",
            "    accuracy                           0.40      2000\n",
            "   macro avg       0.39      0.39      0.39      2000\n",
            "weighted avg       0.40      0.40      0.39      2000\n",
            "\n",
            "Random Forest Confusion Matrix:\n",
            " [[ 97  12  10  11   8   5   7   4  40  14]\n",
            " [ 12  98   5   7   7   5   7   7  14  40]\n",
            " [ 21   5  59  16  34  10  27   7   5   8]\n",
            " [ 10  11  17  41  21  36  31  15   6  13]\n",
            " [  9   2  28  10  80   8  34  11  14  13]\n",
            " [ 12  14  14  25  16  61  17  18   4   5]\n",
            " [  6  10  20  19  37  14  83  11   2   9]\n",
            " [ 10  11  17   7  34  18  12  72   1  22]\n",
            " [ 23  22   5   5   9   9   2   1 116  20]\n",
            " [  6  29   3   7   7   7   5   6  21  84]]\n",
            "Logistic Regression Accuracy: 0.336\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.42      0.40       208\n",
            "           1       0.39      0.38      0.39       202\n",
            "           2       0.26      0.27      0.26       192\n",
            "           3       0.19      0.19      0.19       201\n",
            "           4       0.25      0.24      0.25       209\n",
            "           5       0.26      0.26      0.26       186\n",
            "           6       0.38      0.37      0.38       211\n",
            "           7       0.39      0.36      0.38       204\n",
            "           8       0.47      0.49      0.48       212\n",
            "           9       0.36      0.37      0.36       175\n",
            "\n",
            "    accuracy                           0.34      2000\n",
            "   macro avg       0.33      0.33      0.33      2000\n",
            "weighted avg       0.34      0.34      0.34      2000\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            " [[ 87  12   9  16  14   7   7  10  36  10]\n",
            " [ 15  77  11  12   6   8  10  12  14  37]\n",
            " [ 20   5  52  22  37  14  18  15   4   5]\n",
            " [ 12  17  20  39  16  32  29  16  11   9]\n",
            " [ 16   6  25  17  50  30  30  25   4   6]\n",
            " [ 11   8  26  41  13  48  15  12  10   2]\n",
            " [  6   6  17  27  31  16  78  13   8   9]\n",
            " [ 10  13  26  13  16  14  10  74   6  22]\n",
            " [ 34  21  11  13   6   4   1   3 103  16]\n",
            " [ 13  30   6   2   8  12   6  10  24  64]]\n",
            "SVM Accuracy: 0.443\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.45      0.47       208\n",
            "           1       0.54      0.55      0.55       202\n",
            "           2       0.35      0.32      0.34       192\n",
            "           3       0.33      0.33      0.33       201\n",
            "           4       0.38      0.36      0.37       209\n",
            "           5       0.39      0.36      0.37       186\n",
            "           6       0.38      0.45      0.41       211\n",
            "           7       0.54      0.42      0.47       204\n",
            "           8       0.59      0.65      0.62       212\n",
            "           9       0.43      0.51      0.47       175\n",
            "\n",
            "    accuracy                           0.44      2000\n",
            "   macro avg       0.44      0.44      0.44      2000\n",
            "weighted avg       0.44      0.44      0.44      2000\n",
            "\n",
            "SVM Confusion Matrix:\n",
            " [[ 94  13  14   9  11   1   6   9  35  16]\n",
            " [  8 112   6  11   3   3   8   8  13  30]\n",
            " [ 17   6  62  19  25   9  34   7   5   8]\n",
            " [  7   6  18  67  10  36  24  10   5  18]\n",
            " [ 17   1  23   6  75  11  49  14   6   7]\n",
            " [  6  11  19  34  11  67  18  12   3   5]\n",
            " [  7   6  17  26  30  15  96   6   3   5]\n",
            " [ 10   8  11  17  24  18  12  85   1  18]\n",
            " [ 20  17   4   6   4   6   0   4 138  13]\n",
            " [  5  29   2   6   4   8   5   3  23  90]]\n",
            "\n",
            "Grayscale Images (20% Validation of Training Dataset):\n",
            "==========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-64d5acfcf5d1>:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  random_forest_clf.fit(balanced_x_train_gray.reshape(balanced_x_train_gray.shape[0], -1), y_train_balanced)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy (Grayscale): 0.201\n",
            "Decision Tree Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.26      0.26       208\n",
            "           1       0.24      0.24      0.24       202\n",
            "           2       0.19      0.21      0.20       192\n",
            "           3       0.12      0.11      0.12       201\n",
            "           4       0.16      0.17      0.17       209\n",
            "           5       0.17      0.15      0.16       186\n",
            "           6       0.18      0.18      0.18       211\n",
            "           7       0.20      0.18      0.19       204\n",
            "           8       0.25      0.25      0.25       212\n",
            "           9       0.22      0.26      0.24       175\n",
            "\n",
            "    accuracy                           0.20      2000\n",
            "   macro avg       0.20      0.20      0.20      2000\n",
            "weighted avg       0.20      0.20      0.20      2000\n",
            "\n",
            "Decision Tree Confusion Matrix (Grayscale):\n",
            " [[54  7 17 15 23  8 14 19 38 13]\n",
            " [17 48 10 14 13 11 21 21 18 29]\n",
            " [24 13 40 12 27 17 23 11 12 13]\n",
            " [14 21 25 22 17 22 24 20 19 17]\n",
            " [19 15 23 21 36 20 21 25 18 11]\n",
            " [10 16 19 26 18 28 20 14 18 17]\n",
            " [15 20 35 15 26 23 38 10 12 17]\n",
            " [10 24 13 21 33 21 15 36 11 20]\n",
            " [31 17 17 14 13  7 17 15 54 27]\n",
            " [11 21 16 18 15 10 13 10 15 46]]\n",
            "Random Forest Accuracy (Grayscale): 0.3545\n",
            "Random Forest Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.37      0.36       208\n",
            "           1       0.44      0.45      0.44       202\n",
            "           2       0.29      0.30      0.29       192\n",
            "           3       0.31      0.21      0.25       201\n",
            "           4       0.27      0.30      0.28       209\n",
            "           5       0.33      0.33      0.33       186\n",
            "           6       0.34      0.36      0.35       211\n",
            "           7       0.39      0.28      0.33       204\n",
            "           8       0.46      0.48      0.47       212\n",
            "           9       0.38      0.48      0.42       175\n",
            "\n",
            "    accuracy                           0.35      2000\n",
            "   macro avg       0.35      0.36      0.35      2000\n",
            "weighted avg       0.35      0.35      0.35      2000\n",
            "\n",
            "Random Forest Confusion Matrix (Grayscale):\n",
            " [[ 76  10  18  10  19   4  11   7  40  13]\n",
            " [ 11  91   2   6  11   6  13   8  15  39]\n",
            " [ 26   5  57   8  38  12  29   6   2   9]\n",
            " [ 16  15  14  43  17  36  21  17   6  16]\n",
            " [ 17   6  32   7  63  14  32  17  16   5]\n",
            " [ 19  10  18  18  15  61  12  12  11  10]\n",
            " [ 10  11  20  21  32  15  75  10   8   9]\n",
            " [ 15   9  16  12  32  19  15  57   6  23]\n",
            " [ 23  24  12   8   5  11   5   6 102  16]\n",
            " [  7  28   6   4   5   7  10   6  18  84]]\n",
            "Logistic Regression Accuracy (Grayscale): 0.2495\n",
            "Logistic Regression Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.29      0.28       208\n",
            "           1       0.32      0.34      0.33       202\n",
            "           2       0.23      0.22      0.22       192\n",
            "           3       0.19      0.19      0.19       201\n",
            "           4       0.18      0.18      0.18       209\n",
            "           5       0.22      0.22      0.22       186\n",
            "           6       0.20      0.17      0.18       211\n",
            "           7       0.28      0.23      0.25       204\n",
            "           8       0.32      0.34      0.33       212\n",
            "           9       0.28      0.33      0.30       175\n",
            "\n",
            "    accuracy                           0.25      2000\n",
            "   macro avg       0.25      0.25      0.25      2000\n",
            "weighted avg       0.25      0.25      0.25      2000\n",
            "\n",
            "Logistic Regression Confusion Matrix (Grayscale):\n",
            " [[60  9 17 16 15 12 13 18 37 11]\n",
            " [ 9 68  7  8 11  4 16 15 19 45]\n",
            " [30  7 43 25 26 17 19 12  7  6]\n",
            " [11 15 23 38 23 25 22 18 17  9]\n",
            " [20 11 28 26 37 20 22 13 18 14]\n",
            " [17 11 21 24 21 40 18 17 14  3]\n",
            " [21 26 15 26 28 25 36 17  8  9]\n",
            " [16 12 24 11 21 19 15 46 13 27]\n",
            " [34 20 10 15 13 10  8  5 73 24]\n",
            " [ 9 36  3  8 11  8 13  5 24 58]]\n",
            "SVM Accuracy (Grayscale): 0.3805\n",
            "SVM Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.37      0.38       208\n",
            "           1       0.48      0.48      0.48       202\n",
            "           2       0.32      0.30      0.31       192\n",
            "           3       0.31      0.24      0.27       201\n",
            "           4       0.33      0.35      0.34       209\n",
            "           5       0.35      0.28      0.31       186\n",
            "           6       0.31      0.43      0.36       211\n",
            "           7       0.46      0.34      0.39       204\n",
            "           8       0.47      0.54      0.50       212\n",
            "           9       0.38      0.47      0.42       175\n",
            "\n",
            "    accuracy                           0.38      2000\n",
            "   macro avg       0.38      0.38      0.38      2000\n",
            "weighted avg       0.38      0.38      0.38      2000\n",
            "\n",
            "SVM Confusion Matrix (Grayscale):\n",
            " [[ 76  15  14   9  21   4  16   7  37   9]\n",
            " [  7  96   4  12   4   2  12   9  16  40]\n",
            " [ 19   4  57  16  29   9  45   3   3   7]\n",
            " [  8  10  15  48  17  31  32  16   5  19]\n",
            " [ 18   5  25   8  74  10  35  10  17   7]\n",
            " [ 14   9  18  19  16  52  21  15  16   6]\n",
            " [ 11  10  17  18  32   9  91   7   8   8]\n",
            " [ 14  10  14  11  19  19  20  70   5  22]\n",
            " [ 19  19  12  11   3   6  10   4 115  13]\n",
            " [  3  20   2   5  11   8   9  10  25  82]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define evaluate_model function\n",
        "def evaluate_model(model, x_train, y_train, x_test, y_test):\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    accuracy_scores = []\n",
        "    classification_reports = []\n",
        "    confusion_matrices = []\n",
        "\n",
        "    for train_index, val_index in skf.split(x_train, y_train):\n",
        "        x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "        model.fit(x_train_fold, y_train_fold)\n",
        "        y_pred = model.predict(x_val_fold)\n",
        "        accuracy_scores.append(accuracy_score(y_val_fold, y_pred))\n",
        "        classification_reports.append(classification_report(y_val_fold, y_pred, output_dict=True))\n",
        "        confusion_matrices.append(confusion_matrix(y_val_fold, y_pred))\n",
        "\n",
        "    # Fit the model on the whole training data\n",
        "    model.fit(x_train, y_train)\n",
        "    # Evaluate on testing data\n",
        "    y_pred_test = model.predict(x_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_classification_report = classification_report(y_test, y_pred_test)\n",
        "    test_confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    return np.mean(accuracy_scores), classification_reports, confusion_matrices, test_accuracy, test_classification_report, test_confusion_matrix\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Generate a balanced training dataset with 10 classes and 10,000 total images\n",
        "balanced_x_train = []\n",
        "balanced_y_train = []\n",
        "num_images_per_class = 1000\n",
        "\n",
        "for class_label in range(10):\n",
        "    indices = np.where(y_train == class_label)[0]\n",
        "    np.random.shuffle(indices)\n",
        "    selected_indices = indices[:num_images_per_class]\n",
        "    balanced_x_train.extend(x_train[selected_indices])\n",
        "    balanced_y_train.extend(y_train[selected_indices])\n",
        "\n",
        "balanced_x_train = np.array(balanced_x_train)\n",
        "balanced_y_train = np.array(balanced_y_train)\n",
        "\n",
        "# Flatten images and scale pixel values to the range [0, 1]\n",
        "x_train_flat = balanced_x_train.reshape(balanced_x_train.shape[0], -1) / 255.0\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "# Convert images to grayscale\n",
        "x_train_gray = np.mean(balanced_x_train, axis=3, keepdims=True) / 255.0\n",
        "x_test_gray = np.mean(x_test, axis=3, keepdims=True) / 255.0\n",
        "\n",
        "# Initialize classifiers\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "random_forest_clf = RandomForestClassifier()\n",
        "logistic_regression_clf = LogisticRegression(max_iter=1000)\n",
        "svm_clf = SVC()\n",
        "\n",
        "# Train and evaluate models for color images\n",
        "print(\"Color Images (3-fold Cross-Validation):\")\n",
        "print(\"==========================\")\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy, dt_classification_reports, dt_confusion_matrices, dt_test_accuracy, dt_test_classification_report, dt_test_confusion_matrix = evaluate_model(decision_tree_clf, x_train_flat, balanced_y_train, x_test_flat, y_test)\n",
        "print(\"Decision Tree Mean Cross-Validation Accuracy:\", dt_accuracy)\n",
        "print(\"Decision Tree Test Accuracy:\", dt_test_accuracy)\n",
        "print(\"Decision Tree Test Classification Report:\\n\", dt_test_classification_report)\n",
        "print(\"Decision Tree Test Confusion Matrix:\\n\", dt_test_confusion_matrix)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy, rf_classification_reports, rf_confusion_matrices, rf_test_accuracy, rf_test_classification_report, rf_test_confusion_matrix = evaluate_model(random_forest_clf, x_train_flat, balanced_y_train, x_test_flat, y_test)\n",
        "print(\"Random Forest Mean Cross-Validation Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Test Accuracy:\", rf_test_accuracy)\n",
        "print(\"Random Forest Test Classification Report:\\n\", rf_test_classification_report)\n",
        "print(\"Random Forest Test Confusion Matrix:\\n\", rf_test_confusion_matrix)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy, lr_classification_reports, lr_confusion_matrices, lr_test_accuracy, lr_test_classification_report, lr_test_confusion_matrix = evaluate_model(logistic_regression_clf, x_train_flat, balanced_y_train, x_test_flat, y_test)\n",
        "print(\"Logistic Regression Mean Cross-Validation Accuracy:\", lr_accuracy)\n",
        "print(\"Logistic Regression Test Accuracy:\", lr_test_accuracy)\n",
        "print(\"Logistic Regression Test Classification Report:\\n\", lr_test_classification_report)\n",
        "print(\"Logistic Regression Test Confusion Matrix:\\n\", lr_test_confusion_matrix)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train_flat)\n",
        "x_test_scaled = scaler.transform(x_test_flat)\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_accuracy, svm_classification_reports, svm_confusion_matrices, svm_test_accuracy, svm_test_classification_report, svm_test_confusion_matrix = evaluate_model(svm_clf, x_train_scaled, balanced_y_train, x_test_scaled, y_test)\n",
        "print(\"SVM Mean Cross-Validation Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Test Accuracy:\", svm_test_accuracy)\n",
        "print(\"SVM Test Classification Report:\\n\", svm_test_classification_report)\n",
        "print(\"SVM Test Confusion Matrix:\\n\", svm_test_confusion_matrix)\n",
        "\n",
        "# Train and evaluate models for grayscale images\n",
        "print(\"\\nGrayscale Images (3-fold Cross-Validation):\")\n",
        "print(\"==========================\")\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy_gray, dt_classification_reports_gray, dt_confusion_matrices_gray, dt_test_accuracy_gray, dt_test_classification_report_gray, dt_test_confusion_matrix_gray = evaluate_model(decision_tree_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), balanced_y_train, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "print(\"Decision Tree Mean Cross-Validation Accuracy (Grayscale):\", dt_accuracy_gray)\n",
        "print(\"Decision Tree Test Accuracy (Grayscale):\", dt_test_accuracy_gray)\n",
        "print(\"Decision Tree Test Classification Report (Grayscale):\\n\", dt_test_classification_report_gray)\n",
        "print(\"Decision Tree Test Confusion Matrix (Grayscale):\\n\", dt_test_confusion_matrix_gray)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy_gray, rf_classification_reports_gray, rf_confusion_matrices_gray, rf_test_accuracy_gray, rf_test_classification_report_gray, rf_test_confusion_matrix_gray = evaluate_model(random_forest_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), balanced_y_train, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "print(\"Random Forest Mean Cross-Validation Accuracy (Grayscale):\", rf_accuracy_gray)\n",
        "print(\"Random Forest Test Accuracy (Grayscale):\", rf_test_accuracy_gray)\n",
        "print(\"Random Forest Test Classification Report (Grayscale):\\n\", rf_test_classification_report_gray)\n",
        "print(\"Random Forest Test Confusion Matrix (Grayscale):\\n\", rf_test_confusion_matrix_gray)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy_gray, lr_classification_reports_gray, lr_confusion_matrices_gray, lr_test_accuracy_gray, lr_test_classification_report_gray, lr_test_confusion_matrix_gray = evaluate_model(logistic_regression_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), balanced_y_train, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "print(\"Logistic Regression Mean Cross-Validation Accuracy (Grayscale):\", lr_accuracy_gray)\n",
        "print(\"Logistic Regression Test Accuracy (Grayscale):\", lr_test_accuracy_gray)\n",
        "print(\"Logistic Regression Test Classification Report (Grayscale):\\n\", lr_test_classification_report_gray)\n",
        "print(\"Logistic Regression Test Confusion Matrix (Grayscale):\\n\", lr_test_confusion_matrix_gray)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler_gray = StandardScaler()\n",
        "x_train_gray_scaled = scaler_gray.fit_transform(x_train_gray.reshape(x_train_gray.shape[0], -1))\n",
        "x_test_gray_scaled = scaler_gray.transform(x_test_gray.reshape(x_test_gray.shape[0], -1))\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_accuracy_gray, svm_classification_reports_gray, svm_confusion_matrices_gray, svm_test_accuracy_gray, svm_test_classification_report_gray, svm_test_confusion_matrix_gray = evaluate_model(svm_clf, x_train_gray_scaled, balanced_y_train, x_test_gray_scaled, y_test)\n",
        "print(\"SVM Mean Cross-Validation Accuracy (Grayscale):\", svm_accuracy_gray)\n",
        "print(\"SVM Test Accuracy (Grayscale):\", svm_test_accuracy_gray)\n",
        "print(\"SVM Test Classification Report (Grayscale):\\n\", svm_test_classification_report_gray)\n",
        "print(\"SVM Test Confusion Matrix (Grayscale):\\n\", svm_test_confusion_matrix_gray)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpATnY-tHsf3",
        "outputId": "d2ea2f1b-2e70-40c8-e7af-288d2ceb4972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color Images (3-fold Cross-Validation):\n",
            "==========================\n",
            "Decision Tree Mean Cross-Validation Accuracy: 0.22290072438557593\n",
            "Decision Tree Test Accuracy: 0.2362\n",
            "Decision Tree Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31      1000\n",
            "           1       0.26      0.26      0.26      1000\n",
            "           2       0.18      0.20      0.19      1000\n",
            "           3       0.16      0.14      0.15      1000\n",
            "           4       0.19      0.20      0.19      1000\n",
            "           5       0.20      0.20      0.20      1000\n",
            "           6       0.24      0.24      0.24      1000\n",
            "           7       0.23      0.21      0.22      1000\n",
            "           8       0.34      0.34      0.34      1000\n",
            "           9       0.27      0.26      0.26      1000\n",
            "\n",
            "    accuracy                           0.24     10000\n",
            "   macro avg       0.24      0.24      0.24     10000\n",
            "weighted avg       0.24      0.24      0.24     10000\n",
            "\n",
            "Decision Tree Test Confusion Matrix:\n",
            " [[318  70 109  50  64  43  46  69 162  69]\n",
            " [ 69 255  73  90  57  69  64  75  97 151]\n",
            " [102  69 199  77 130 107 124  81  69  42]\n",
            " [ 70  56 126 143 106 165 128  89  48  69]\n",
            " [ 61  58 169  83 196  90 143  99  47  54]\n",
            " [ 59  66 116 132  97 204 104 110  53  59]\n",
            " [ 33  64 128 129 159 105 237  67  34  44]\n",
            " [ 78  61  83  77 114 113  81 212  61 120]\n",
            " [157  96  72  49  50  66  25  49 338  98]\n",
            " [107 177  58  68  46  60  54  75  95 260]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-88ad1c83b991>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-5-88ad1c83b991>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-5-88ad1c83b991>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-5-88ad1c83b991>:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train, y_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Cross-Validation Accuracy: 0.4008996280551871\n",
            "Random Forest Test Accuracy: 0.4196\n",
            "Random Forest Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.53      0.50      1000\n",
            "           1       0.46      0.48      0.47      1000\n",
            "           2       0.32      0.29      0.30      1000\n",
            "           3       0.28      0.22      0.25      1000\n",
            "           4       0.36      0.36      0.36      1000\n",
            "           5       0.39      0.36      0.37      1000\n",
            "           6       0.41      0.48      0.44      1000\n",
            "           7       0.49      0.39      0.43      1000\n",
            "           8       0.54      0.57      0.55      1000\n",
            "           9       0.44      0.51      0.48      1000\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.41      0.42      0.42     10000\n",
            "weighted avg       0.41      0.42      0.42     10000\n",
            "\n",
            "Random Forest Test Confusion Matrix:\n",
            " [[526  42  55  26  23  20  28  28 188  64]\n",
            " [ 43 478  26  49  32  41  46  28  74 183]\n",
            " [129  48 288  77 144  59 125  61  30  39]\n",
            " [ 72  58  90 221  90 180 133  62  20  74]\n",
            " [ 71  26 148  62 364  52 151  77  24  25]\n",
            " [ 49  45  94 142  83 364  90  75  27  31]\n",
            " [ 13  39 105  77 141  66 479  26   7  47]\n",
            " [ 60  47  61  55 102  93  62 389  30 101]\n",
            " [103  96  18  32  25  39  15  19 575  78]\n",
            " [ 51 171  14  40  15  28  35  35  99 512]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Mean Cross-Validation Accuracy: 0.315000066293372\n",
            "Logistic Regression Test Accuracy: 0.3288\n",
            "Logistic Regression Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.38      0.38      1000\n",
            "           1       0.38      0.37      0.37      1000\n",
            "           2       0.25      0.25      0.25      1000\n",
            "           3       0.23      0.20      0.21      1000\n",
            "           4       0.29      0.29      0.29      1000\n",
            "           5       0.24      0.25      0.24      1000\n",
            "           6       0.35      0.34      0.35      1000\n",
            "           7       0.37      0.34      0.36      1000\n",
            "           8       0.41      0.48      0.44      1000\n",
            "           9       0.39      0.38      0.38      1000\n",
            "\n",
            "    accuracy                           0.33     10000\n",
            "   macro avg       0.33      0.33      0.33     10000\n",
            "weighted avg       0.33      0.33      0.33     10000\n",
            "\n",
            "Logistic Regression Test Confusion Matrix:\n",
            " [[377  49  68  38  37  43  24  52 236  76]\n",
            " [ 71 367  51  48  37  48  52  54  94 178]\n",
            " [ 89  42 251  75 161 103 116  73  58  32]\n",
            " [ 48  74 107 205 104 186 125  52  47  52]\n",
            " [ 49  26 144  77 293 113 130 104  35  29]\n",
            " [ 41  54 129 168 102 246  85  94  54  27]\n",
            " [ 23  43 129 150 114  95 345  55  14  32]\n",
            " [ 65  48  82  73 112  97  52 342  49  80]\n",
            " [153  92  35  33  19  48  17  23 485  95]\n",
            " [ 77 180  21  40  41  33  41  72 118 377]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Mean Cross-Validation Accuracy: 0.45139972905508907\n",
            "SVM Test Accuracy: 0.4753\n",
            "SVM Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.53      0.54      1000\n",
            "           1       0.56      0.58      0.57      1000\n",
            "           2       0.35      0.34      0.35      1000\n",
            "           3       0.31      0.32      0.32      1000\n",
            "           4       0.42      0.38      0.40      1000\n",
            "           5       0.44      0.36      0.40      1000\n",
            "           6       0.45      0.58      0.51      1000\n",
            "           7       0.57      0.46      0.51      1000\n",
            "           8       0.58      0.64      0.61      1000\n",
            "           9       0.53      0.55      0.54      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.47      0.48      0.47     10000\n",
            "weighted avg       0.47      0.48      0.47     10000\n",
            "\n",
            "SVM Test Confusion Matrix:\n",
            " [[529  36  65  24  22  14  29  27 186  68]\n",
            " [ 31 584  22  52  11  23  28  29  62 158]\n",
            " [101  27 345  99 142  52 134  56  27  17]\n",
            " [ 45  46  87 318  60 184 141  45  26  48]\n",
            " [ 62  19 165  70 377  39 157  68  27  16]\n",
            " [ 27  22 106 203  70 364 105  49  31  23]\n",
            " [ 13  29 105  84  97  43 579  22  11  17]\n",
            " [ 46  39  60  81  97  66  53 464  25  69]\n",
            " [ 82  80  23  30  19  22  14  23 639  68]\n",
            " [ 35 164  15  51   9  19  39  38  76 554]]\n",
            "\n",
            "Grayscale Images (3-fold Cross-Validation):\n",
            "==========================\n",
            "Decision Tree Mean Cross-Validation Accuracy (Grayscale): 0.19519975392860223\n",
            "Decision Tree Test Accuracy (Grayscale): 0.2046\n",
            "Decision Tree Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.25      0.25      1000\n",
            "           1       0.22      0.21      0.21      1000\n",
            "           2       0.17      0.18      0.18      1000\n",
            "           3       0.14      0.13      0.13      1000\n",
            "           4       0.17      0.17      0.17      1000\n",
            "           5       0.19      0.19      0.19      1000\n",
            "           6       0.19      0.18      0.19      1000\n",
            "           7       0.19      0.19      0.19      1000\n",
            "           8       0.28      0.30      0.29      1000\n",
            "           9       0.26      0.23      0.24      1000\n",
            "\n",
            "    accuracy                           0.20     10000\n",
            "   macro avg       0.20      0.20      0.20     10000\n",
            "weighted avg       0.20      0.20      0.20     10000\n",
            "\n",
            "Decision Tree Test Confusion Matrix (Grayscale):\n",
            " [[253  50 116  69  89  71  67  71 157  57]\n",
            " [ 66 209  68  75  62  83  88  67 114 168]\n",
            " [114  63 184 107 117  88  94  96  75  62]\n",
            " [ 94  73 105 134 120 130 120 109  57  58]\n",
            " [ 88  57 156  87 173 121 122  97  52  47]\n",
            " [ 75  58 105 158  94 189  81 111  79  50]\n",
            " [ 70  81 138 120 122  90 183  88  50  58]\n",
            " [ 84  79  86  96 132 110  72 189  73  79]\n",
            " [123  97  66  69  60  67  57  67 301  93]\n",
            " [ 57 179  70  77  40  67  80  92 107 231]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-88ad1c83b991>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-5-88ad1c83b991>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-5-88ad1c83b991>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-5-88ad1c83b991>:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train, y_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Cross-Validation Accuracy (Grayscale): 0.3503997070372904\n",
            "Random Forest Test Accuracy (Grayscale): 0.3704\n",
            "Random Forest Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.44      0.41      1000\n",
            "           1       0.42      0.44      0.43      1000\n",
            "           2       0.28      0.27      0.28      1000\n",
            "           3       0.24      0.18      0.21      1000\n",
            "           4       0.31      0.34      0.33      1000\n",
            "           5       0.38      0.33      0.35      1000\n",
            "           6       0.35      0.39      0.37      1000\n",
            "           7       0.42      0.34      0.38      1000\n",
            "           8       0.47      0.50      0.48      1000\n",
            "           9       0.41      0.46      0.43      1000\n",
            "\n",
            "    accuracy                           0.37     10000\n",
            "   macro avg       0.37      0.37      0.37     10000\n",
            "weighted avg       0.37      0.37      0.37     10000\n",
            "\n",
            "Random Forest Test Confusion Matrix (Grayscale):\n",
            " [[439  29  96  26  65  20  45  38 182  60]\n",
            " [ 42 438  27  43  38  35  79  40  72 186]\n",
            " [135  49 273  71 143  73 121  61  40  34]\n",
            " [ 84  61  93 181 113 156 137  65  33  77]\n",
            " [ 87  34 148  58 344  42 135  77  50  25]\n",
            " [ 73  39  92 141  93 327  80  71  40  44]\n",
            " [ 55  61 105  92 139  55 393  33  18  49]\n",
            " [ 68  54  68  66 101  88  55 345  42 113]\n",
            " [103  94  34  41  31  46  27  43 501  80]\n",
            " [ 49 187  24  39  29  28  44  40  97 463]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Mean Cross-Validation Accuracy (Grayscale): 0.24530041486452184\n",
            "Logistic Regression Test Accuracy (Grayscale): 0.2486\n",
            "Logistic Regression Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.31      0.30      1000\n",
            "           1       0.30      0.30      0.30      1000\n",
            "           2       0.17      0.17      0.17      1000\n",
            "           3       0.17      0.14      0.15      1000\n",
            "           4       0.19      0.18      0.18      1000\n",
            "           5       0.24      0.23      0.23      1000\n",
            "           6       0.22      0.23      0.23      1000\n",
            "           7       0.24      0.22      0.23      1000\n",
            "           8       0.31      0.35      0.33      1000\n",
            "           9       0.33      0.35      0.34      1000\n",
            "\n",
            "    accuracy                           0.25     10000\n",
            "   macro avg       0.25      0.25      0.25     10000\n",
            "weighted avg       0.25      0.25      0.25     10000\n",
            "\n",
            "Logistic Regression Test Confusion Matrix (Grayscale):\n",
            " [[309  45  87  45  76  65  47  78 180  68]\n",
            " [ 55 297  46  44  57  37 114  69  97 184]\n",
            " [131  51 172 107 129  84 113 105  71  37]\n",
            " [ 81  75 123 140 123 145 133  68  60  52]\n",
            " [ 66  41 155 104 183 109 139 111  47  45]\n",
            " [ 74  45 129 107 117 227  95  87  78  41]\n",
            " [ 64  95  96 125 114 102 234  63  40  67]\n",
            " [ 67  63 113  80 119  83  67 222  96  90]\n",
            " [142 103  46  45  20  58  46  63 355 122]\n",
            " [ 58 169  40  38  42  32  66  75 133 347]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define evaluate_model function\n",
        "def evaluate_model(model, x_train, y_train, x_test, y_test):\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    accuracy_scores = []\n",
        "    classification_reports = []\n",
        "    confusion_matrices = []\n",
        "\n",
        "    for train_index, val_index in skf.split(x_train, y_train):\n",
        "        x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "        model.fit(x_train_fold, y_train_fold)\n",
        "        y_pred = model.predict(x_val_fold)\n",
        "        accuracy_scores.append(accuracy_score(y_val_fold, y_pred))\n",
        "        classification_reports.append(classification_report(y_val_fold, y_pred, output_dict=True))\n",
        "        confusion_matrices.append(confusion_matrix(y_val_fold, y_pred))\n",
        "\n",
        "    # Fit the model on the whole training data\n",
        "    model.fit(x_train, y_train)\n",
        "    # Evaluate on testing data\n",
        "    y_pred_test = model.predict(x_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_classification_report = classification_report(y_test, y_pred_test)\n",
        "    test_confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    return np.mean(accuracy_scores), classification_reports, confusion_matrices, test_accuracy, test_classification_report, test_confusion_matrix\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Generate a balanced training dataset with 10 classes and 10,000 total images\n",
        "balanced_x_train = []\n",
        "balanced_y_train = []\n",
        "num_images_per_class = 1000\n",
        "\n",
        "for class_label in range(10):\n",
        "    indices = np.where(y_train == class_label)[0]\n",
        "    np.random.shuffle(indices)\n",
        "    selected_indices = indices[:num_images_per_class]\n",
        "    balanced_x_train.extend(x_train[selected_indices])\n",
        "    balanced_y_train.extend(y_train[selected_indices])\n",
        "\n",
        "balanced_x_train = np.array(balanced_x_train)\n",
        "balanced_y_train = np.array(balanced_y_train)\n",
        "\n",
        "# Flatten images and scale pixel values to the range [0, 1]\n",
        "x_train_flat = balanced_x_train.reshape(balanced_x_train.shape[0], -1) / 255.0\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "# Convert images to grayscale\n",
        "x_train_gray = np.mean(balanced_x_train, axis=3, keepdims=True) / 255.0\n",
        "x_test_gray = np.mean(x_test, axis=3, keepdims=True) / 255.0\n",
        "\n",
        "# Initialize classifiers\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "random_forest_clf = RandomForestClassifier()\n",
        "logistic_regression_clf = LogisticRegression(max_iter=1000)\n",
        "svm_clf = SVC()\n",
        "\n",
        "# Train and evaluate models for color images\n",
        "print(\"Color Images (5-fold Cross-Validation):\")\n",
        "print(\"==========================\")\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy, dt_classification_reports, dt_confusion_matrices, dt_test_accuracy, dt_test_classification_report, dt_test_confusion_matrix = evaluate_model(decision_tree_clf, x_train_flat, balanced_y_train, x_test_flat, y_test)\n",
        "print(\"Decision Tree Mean Cross-Validation Accuracy:\", dt_accuracy)\n",
        "print(\"Decision Tree Test Accuracy:\", dt_test_accuracy)\n",
        "print(\"Decision Tree Test Classification Report:\\n\", dt_test_classification_report)\n",
        "print(\"Decision Tree Test Confusion Matrix:\\n\", dt_test_confusion_matrix)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy, rf_classification_reports, rf_confusion_matrices, rf_test_accuracy, rf_test_classification_report, rf_test_confusion_matrix = evaluate_model(random_forest_clf, x_train_flat, balanced_y_train, x_test_flat, y_test)\n",
        "print(\"Random Forest Mean Cross-Validation Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Test Accuracy:\", rf_test_accuracy)\n",
        "print(\"Random Forest Test Classification Report:\\n\", rf_test_classification_report)\n",
        "print(\"Random Forest Test Confusion Matrix:\\n\", rf_test_confusion_matrix)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy, lr_classification_reports, lr_confusion_matrices, lr_test_accuracy, lr_test_classification_report, lr_test_confusion_matrix = evaluate_model(logistic_regression_clf, x_train_flat, balanced_y_train, x_test_flat, y_test)\n",
        "print(\"Logistic Regression Mean Cross-Validation Accuracy:\", lr_accuracy)\n",
        "print(\"Logistic Regression Test Accuracy:\", lr_test_accuracy)\n",
        "print(\"Logistic Regression Test Classification Report:\\n\", lr_test_classification_report)\n",
        "print(\"Logistic Regression Test Confusion Matrix:\\n\", lr_test_confusion_matrix)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train_flat)\n",
        "x_test_scaled = scaler.transform(x_test_flat)\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_accuracy, svm_classification_reports, svm_confusion_matrices, svm_test_accuracy, svm_test_classification_report, svm_test_confusion_matrix = evaluate_model(svm_clf, x_train_scaled, balanced_y_train, x_test_scaled, y_test)\n",
        "print(\"SVM Mean Cross-Validation Accuracy:\", svm_accuracy)\n",
        "print(\"SVM Test Accuracy:\", svm_test_accuracy)\n",
        "print(\"SVM Test Classification Report:\\n\", svm_test_classification_report)\n",
        "print(\"SVM Test Confusion Matrix:\\n\", svm_test_confusion_matrix)\n",
        "\n",
        "# Train and evaluate models for grayscale images\n",
        "print(\"\\nGrayscale Images (5-fold Cross-Validation):\")\n",
        "print(\"==========================\")\n",
        "# Evaluate Decision Tree\n",
        "dt_accuracy_gray, dt_classification_reports_gray, dt_confusion_matrices_gray, dt_test_accuracy_gray, dt_test_classification_report_gray, dt_test_confusion_matrix_gray = evaluate_model(decision_tree_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), balanced_y_train, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "print(\"Decision Tree Mean Cross-Validation Accuracy (Grayscale):\", dt_accuracy_gray)\n",
        "print(\"Decision Tree Test Accuracy (Grayscale):\", dt_test_accuracy_gray)\n",
        "print(\"Decision Tree Test Classification Report (Grayscale):\\n\", dt_test_classification_report_gray)\n",
        "print(\"Decision Tree Test Confusion Matrix (Grayscale):\\n\", dt_test_confusion_matrix_gray)\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_accuracy_gray, rf_classification_reports_gray, rf_confusion_matrices_gray, rf_test_accuracy_gray, rf_test_classification_report_gray, rf_test_confusion_matrix_gray = evaluate_model(random_forest_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), balanced_y_train, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "print(\"Random Forest Mean Cross-Validation Accuracy (Grayscale):\", rf_accuracy_gray)\n",
        "print(\"Random Forest Test Accuracy (Grayscale):\", rf_test_accuracy_gray)\n",
        "print(\"Random Forest Test Classification Report (Grayscale):\\n\", rf_test_classification_report_gray)\n",
        "print(\"Random Forest Test Confusion Matrix (Grayscale):\\n\", rf_test_confusion_matrix_gray)\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "lr_accuracy_gray, lr_classification_reports_gray, lr_confusion_matrices_gray, lr_test_accuracy_gray, lr_test_classification_report_gray, lr_test_confusion_matrix_gray = evaluate_model(logistic_regression_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), balanced_y_train, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test)\n",
        "print(\"Logistic Regression Mean Cross-Validation Accuracy (Grayscale):\", lr_accuracy_gray)\n",
        "print(\"Logistic Regression Test Accuracy (Grayscale):\", lr_test_accuracy_gray)\n",
        "print(\"Logistic Regression Test Classification Report (Grayscale):\\n\", lr_test_classification_report_gray)\n",
        "print(\"Logistic Regression Test Confusion Matrix (Grayscale):\\n\", lr_test_confusion_matrix_gray)\n",
        "\n",
        "# Scale features for SVM\n",
        "scaler_gray = StandardScaler()\n",
        "x_train_gray_scaled = scaler_gray.fit_transform(x_train_gray.reshape(x_train_gray.shape[0], -1))\n",
        "x_test_gray_scaled = scaler_gray.transform(x_test_gray.reshape(x_test_gray.shape[0], -1))\n",
        "\n",
        "# Evaluate SVM\n",
        "svm_accuracy_gray, svm_classification_reports_gray, svm_confusion_matrices_gray, svm_test_accuracy_gray, svm_test_classification_report_gray, svm_test_confusion_matrix_gray = evaluate_model(svm_clf, x_train_gray_scaled, balanced_y_train, x_test_gray_scaled, y_test)\n",
        "print(\"SVM Mean Cross-Validation Accuracy (Grayscale):\", svm_accuracy_gray)\n",
        "print(\"SVM Test Accuracy (Grayscale):\", svm_test_accuracy_gray)\n",
        "print(\"SVM Test Classification Report (Grayscale):\\n\", svm_test_classification_report_gray)\n",
        "print(\"SVM Test Confusion Matrix (Grayscale):\\n\", svm_test_confusion_matrix_gray)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-UrgC1BJGc_",
        "outputId": "3eb49ef3-11b3-4992-dcc9-d40508adba2a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Color Images (5-fold Cross-Validation):\n",
            "==========================\n",
            "Decision Tree Mean Cross-Validation Accuracy: 0.2311\n",
            "Decision Tree Test Accuracy: 0.2341\n",
            "Decision Tree Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.35      0.33      1000\n",
            "           1       0.25      0.23      0.24      1000\n",
            "           2       0.15      0.17      0.16      1000\n",
            "           3       0.15      0.14      0.14      1000\n",
            "           4       0.20      0.20      0.20      1000\n",
            "           5       0.22      0.21      0.22      1000\n",
            "           6       0.24      0.25      0.25      1000\n",
            "           7       0.24      0.23      0.23      1000\n",
            "           8       0.32      0.33      0.32      1000\n",
            "           9       0.26      0.23      0.24      1000\n",
            "\n",
            "    accuracy                           0.23     10000\n",
            "   macro avg       0.23      0.23      0.23     10000\n",
            "weighted avg       0.23      0.23      0.23     10000\n",
            "\n",
            "Decision Tree Test Confusion Matrix:\n",
            " [[354  76 104  45  58  57  37  51 143  75]\n",
            " [ 79 225  79  75  50  85  60  66 122 159]\n",
            " [109  63 174 114 137  74 128  97  67  37]\n",
            " [ 71  59 129 142 105 144 148  96  49  57]\n",
            " [ 71  49 167 106 199  97 139  91  49  32]\n",
            " [ 65  60 102 147  92 214 114 109  42  55]\n",
            " [ 50  51 140 125 141 104 252  62  32  43]\n",
            " [ 71  67  95  85 106  97  93 225  75  86]\n",
            " [160 100  62  67  51  48  24  56 326 106]\n",
            " [117 136  84  65  44  66  62  88 108 230]]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train, y_train)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Mean Cross-Validation Accuracy: 0.41129999999999994\n",
            "Random Forest Test Accuracy: 0.4177\n",
            "Random Forest Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.50      0.50      1000\n",
            "           1       0.49      0.49      0.49      1000\n",
            "           2       0.31      0.25      0.28      1000\n",
            "           3       0.28      0.20      0.24      1000\n",
            "           4       0.35      0.39      0.37      1000\n",
            "           5       0.35      0.35      0.35      1000\n",
            "           6       0.45      0.53      0.49      1000\n",
            "           7       0.42      0.38      0.40      1000\n",
            "           8       0.54      0.58      0.56      1000\n",
            "           9       0.43      0.51      0.47      1000\n",
            "\n",
            "    accuracy                           0.42     10000\n",
            "   macro avg       0.41      0.42      0.41     10000\n",
            "weighted avg       0.41      0.42      0.41     10000\n",
            "\n",
            "Random Forest Test Confusion Matrix:\n",
            " [[504  37  59  21  31  28  25  36 183  76]\n",
            " [ 33 490  19  44  30  37  47  35  72 193]\n",
            " [119  50 248  75 171  80 136  59  29  33]\n",
            " [ 62  39  86 203  92 208 121  86  22  81]\n",
            " [ 57  22 136  55 385  55 148  89  24  29]\n",
            " [ 39  36  88 144  99 352  79 101  29  33]\n",
            " [ 19  27  80  62 123  70 533  36  10  40]\n",
            " [ 53  47  55  60 120  98  56 375  31 105]\n",
            " [ 98  98  16  31  18  42  12  28 576  81]\n",
            " [ 48 162  16  29  19  32  35  53  95 511]]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Mean Cross-Validation Accuracy: 0.3142\n",
            "Logistic Regression Test Accuracy: 0.3278\n",
            "Logistic Regression Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.41      0.40      1000\n",
            "           1       0.39      0.38      0.39      1000\n",
            "           2       0.25      0.24      0.25      1000\n",
            "           3       0.22      0.22      0.22      1000\n",
            "           4       0.27      0.26      0.26      1000\n",
            "           5       0.24      0.25      0.24      1000\n",
            "           6       0.34      0.36      0.35      1000\n",
            "           7       0.36      0.34      0.35      1000\n",
            "           8       0.42      0.45      0.43      1000\n",
            "           9       0.38      0.36      0.37      1000\n",
            "\n",
            "    accuracy                           0.33     10000\n",
            "   macro avg       0.33      0.33      0.33     10000\n",
            "weighted avg       0.33      0.33      0.33     10000\n",
            "\n",
            "Logistic Regression Test Confusion Matrix:\n",
            " [[409  67  71  41  29  46  29  52 188  68]\n",
            " [ 74 384  36  36  46  64  58  52  83 167]\n",
            " [ 91  39 242  90 162 102 117  84  47  26]\n",
            " [ 31  56  95 218  99 195 131  74  45  56]\n",
            " [ 58  29 157  80 260 107 148  98  29  34]\n",
            " [ 50  48 106 197  92 251  98  76  57  25]\n",
            " [ 15  31 107 149 117  99 365  67  19  31]\n",
            " [ 52  45  92  82 125 109  47 337  45  66]\n",
            " [165  98  34  42  20  44  17  21 451 108]\n",
            " [ 87 183  35  41  24  33  58  63 115 361]]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Mean Cross-Validation Accuracy: 0.4572\n",
            "SVM Test Accuracy: 0.479\n",
            "SVM Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.54      0.55      1000\n",
            "           1       0.56      0.56      0.56      1000\n",
            "           2       0.37      0.31      0.34      1000\n",
            "           3       0.34      0.33      0.34      1000\n",
            "           4       0.39      0.41      0.40      1000\n",
            "           5       0.43      0.38      0.40      1000\n",
            "           6       0.46      0.58      0.51      1000\n",
            "           7       0.56      0.47      0.51      1000\n",
            "           8       0.58      0.63      0.61      1000\n",
            "           9       0.51      0.59      0.55      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.48      0.48      0.48     10000\n",
            "weighted avg       0.48      0.48      0.48     10000\n",
            "\n",
            "SVM Test Confusion Matrix:\n",
            " [[538  44  54  28  32  15  26  33 162  68]\n",
            " [ 31 557  18  34  22  27  34  29  69 179]\n",
            " [ 96  29 308  91 178  67 130  51  27  23]\n",
            " [ 42  30  74 330  76 172 133  47  32  64]\n",
            " [ 46  22 132  60 412  54 159  70  26  19]\n",
            " [ 26  16  76 194  77 378 107  66  28  32]\n",
            " [ 10  18  70  80 131  49 584  23  11  24]\n",
            " [ 38  39  52  77 106  70  54 465  23  76]\n",
            " [ 85  80  26  25  18  31  12  17 631  75]\n",
            " [ 35 152  15  43  13  17  32  36  70 587]]\n",
            "\n",
            "Grayscale Images (5-fold Cross-Validation):\n",
            "==========================\n",
            "Decision Tree Mean Cross-Validation Accuracy (Grayscale): 0.2021\n",
            "Decision Tree Test Accuracy (Grayscale): 0.2137\n",
            "Decision Tree Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.26      0.26      1000\n",
            "           1       0.24      0.22      0.23      1000\n",
            "           2       0.15      0.16      0.16      1000\n",
            "           3       0.15      0.15      0.15      1000\n",
            "           4       0.19      0.21      0.20      1000\n",
            "           5       0.21      0.19      0.20      1000\n",
            "           6       0.23      0.23      0.23      1000\n",
            "           7       0.20      0.19      0.20      1000\n",
            "           8       0.27      0.29      0.28      1000\n",
            "           9       0.26      0.23      0.24      1000\n",
            "\n",
            "    accuracy                           0.21     10000\n",
            "   macro avg       0.21      0.21      0.21     10000\n",
            "weighted avg       0.21      0.21      0.21     10000\n",
            "\n",
            "Decision Tree Test Confusion Matrix (Grayscale):\n",
            " [[264  76 128  54  84  59  60  71 142  62]\n",
            " [ 80 222  70  83  85  65  85  73 101 136]\n",
            " [115  58 163 106 150  91 101  99  66  51]\n",
            " [ 78  73 102 146 109 138 114 106  57  77]\n",
            " [ 86  62 150  82 208  97 113  85  64  53]\n",
            " [ 79  53  84 146 121 194 103  92  78  50]\n",
            " [ 71  67 125 101 117 101 229  72  56  61]\n",
            " [ 72  76 111  85 116  87  77 193  85  98]\n",
            " [133  95  73  69  74  52  59  75 288  82]\n",
            " [ 79 143  69  74  51  58  73 105 118 230]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train_fold, y_train_fold)\n",
            "<ipython-input-6-ae0a8a531c4a>:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(x_train, y_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Cross-Validation Accuracy (Grayscale): 0.3596\n",
            "Random Forest Test Accuracy (Grayscale): 0.3737\n",
            "Random Forest Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.40      0.41      1000\n",
            "           1       0.44      0.42      0.43      1000\n",
            "           2       0.32      0.29      0.30      1000\n",
            "           3       0.27      0.17      0.21      1000\n",
            "           4       0.30      0.36      0.33      1000\n",
            "           5       0.36      0.33      0.34      1000\n",
            "           6       0.38      0.40      0.39      1000\n",
            "           7       0.39      0.36      0.37      1000\n",
            "           8       0.45      0.50      0.47      1000\n",
            "           9       0.40      0.49      0.44      1000\n",
            "\n",
            "    accuracy                           0.37     10000\n",
            "   macro avg       0.37      0.37      0.37     10000\n",
            "weighted avg       0.37      0.37      0.37     10000\n",
            "\n",
            "Random Forest Test Confusion Matrix (Grayscale):\n",
            " [[404  38  92  20  73  26  49  43 201  54]\n",
            " [ 33 423  18  29  39  42  85  46  68 217]\n",
            " [110  50 290  62 160  64 120  61  42  41]\n",
            " [ 72  51  90 175 119 174 118  81  33  87]\n",
            " [ 66  33 146  45 362  53 119 103  43  30]\n",
            " [ 64  35  94 135  94 331  73  89  43  42]\n",
            " [ 47  48  77  74 171  63 404  43  21  52]\n",
            " [ 58  55  63  48 133  91  40 356  50 106]\n",
            " [ 84  77  25  41  42  60  24  45 497 105]\n",
            " [ 49 153  21  22  33  26  42  55 104 495]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Mean Cross-Validation Accuracy (Grayscale): 0.2464\n",
            "Logistic Regression Test Accuracy (Grayscale): 0.2449\n",
            "Logistic Regression Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.29      0.29      1000\n",
            "           1       0.30      0.29      0.30      1000\n",
            "           2       0.17      0.15      0.16      1000\n",
            "           3       0.18      0.16      0.17      1000\n",
            "           4       0.18      0.17      0.17      1000\n",
            "           5       0.23      0.23      0.23      1000\n",
            "           6       0.22      0.23      0.23      1000\n",
            "           7       0.22      0.22      0.22      1000\n",
            "           8       0.29      0.34      0.31      1000\n",
            "           9       0.33      0.36      0.35      1000\n",
            "\n",
            "    accuracy                           0.24     10000\n",
            "   macro avg       0.24      0.24      0.24     10000\n",
            "weighted avg       0.24      0.24      0.24     10000\n",
            "\n",
            "Logistic Regression Test Confusion Matrix (Grayscale):\n",
            " [[288  52  80  60  68  76  48  85 174  69]\n",
            " [ 48 294  42  48  70  41 103  70  87 197]\n",
            " [123  48 152  92 139 104 118 108  76  40]\n",
            " [ 71  53  88 161 124 158 108 102  69  66]\n",
            " [ 72  44 126  93 170 129 148 112  64  42]\n",
            " [ 90  48 107 124  95 231  92 101  79  33]\n",
            " [ 64  93  88 124 111  92 229  92  43  64]\n",
            " [ 66  58 105  80 121  94  75 222  97  82]\n",
            " [131  98  49  58  22  62  35  60 339 146]\n",
            " [ 45 181  34  39  33  29  76  68 132 363]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Mean Cross-Validation Accuracy (Grayscale): 0.3889\n",
            "SVM Test Accuracy (Grayscale): 0.4031\n",
            "SVM Test Classification Report (Grayscale):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.37      0.39      1000\n",
            "           1       0.50      0.47      0.48      1000\n",
            "           2       0.31      0.23      0.26      1000\n",
            "           3       0.31      0.24      0.27      1000\n",
            "           4       0.32      0.42      0.36      1000\n",
            "           5       0.41      0.34      0.37      1000\n",
            "           6       0.38      0.49      0.43      1000\n",
            "           7       0.47      0.38      0.42      1000\n",
            "           8       0.45      0.56      0.50      1000\n",
            "           9       0.46      0.53      0.49      1000\n",
            "\n",
            "    accuracy                           0.40     10000\n",
            "   macro avg       0.40      0.40      0.40     10000\n",
            "weighted avg       0.40      0.40      0.40     10000\n",
            "\n",
            "SVM Test Confusion Matrix (Grayscale):\n",
            " [[373  40  82  26  98  16  62  40 200  63]\n",
            " [ 26 465  11  39  38  21  69  37 108 186]\n",
            " [101  25 230  73 207  81 154  51  48  30]\n",
            " [ 63  35  64 239 115 151 145  64  49  75]\n",
            " [ 60  29 123  42 416  44 139  65  58  24]\n",
            " [ 61  23  76 141 110 342 102  61  46  38]\n",
            " [ 44  32  61  75 145  56 495  26  29  37]\n",
            " [ 46  45  62  68 114  65  59 380  64  97]\n",
            " [ 80  82  26  35  38  41  31  37 560  70]\n",
            " [ 35 145  18  29  22  18  54  52  96 531]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define evaluate_model function\n",
        "def evaluate_model(model, x_train, y_train, x_test, y_test):\n",
        "    loo = LeaveOneOut()\n",
        "    accuracy_scores = []\n",
        "    classification_reports = []\n",
        "    confusion_matrices = []\n",
        "\n",
        "    for train_index, val_index in loo.split(x_train):\n",
        "        x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "        model.fit(x_train_fold, y_train_fold)\n",
        "        y_pred = model.predict(x_val_fold)\n",
        "        accuracy_scores.append(accuracy_score(y_val_fold, y_pred))\n",
        "        classification_reports.append(classification_report(y_val_fold, y_pred, output_dict=True))\n",
        "        confusion_matrices.append(confusion_matrix(y_val_fold, y_pred))\n",
        "\n",
        "    # Fit the model on the whole training data\n",
        "    model.fit(x_train, y_train)\n",
        "    # Evaluate on testing data\n",
        "    y_pred_test = model.predict(x_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    test_classification_report = classification_report(y_test, y_pred_test)\n",
        "    test_confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "    return np.mean(accuracy_scores), classification_reports, confusion_matrices, test_accuracy, test_classification_report, test_confusion_matrix\n",
        "\n",
        "def main():\n",
        "    # Load CIFAR-10 dataset\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "    # Select 5000 training images randomly\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    indices = np.random.choice(len(x_train), 5000, replace=False)\n",
        "    x_train_selected = x_train[indices]\n",
        "    y_train_selected = y_train[indices]\n",
        "\n",
        "    # Flatten images and scale pixel values to the range [0, 1]\n",
        "    x_train_flat = x_train_selected.reshape(x_train_selected.shape[0], -1) / 255.0\n",
        "    x_test_flat = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
        "\n",
        "    # Initialize classifiers\n",
        "    decision_tree_clf = DecisionTreeClassifier()\n",
        "    random_forest_clf = RandomForestClassifier()\n",
        "    logistic_regression_clf = LogisticRegression(max_iter=1000)\n",
        "    svm_clf = SVC()\n",
        "\n",
        "    # Train and evaluate models for color images\n",
        "    print(\"Color Images (LOOCV - 5000 training images):\")\n",
        "    print(\"==========================\")\n",
        "    evaluate_and_print_results(decision_tree_clf, x_train_flat, y_train_selected, x_test_flat, y_test, \"Decision Tree\")\n",
        "    evaluate_and_print_results(random_forest_clf, x_train_flat, y_train_selected, x_test_flat, y_test, \"Random Forest\")\n",
        "    evaluate_and_print_results(logistic_regression_clf, x_train_flat, y_train_selected, x_test_flat, y_test, \"Logistic Regression\")\n",
        "    evaluate_and_print_results(svm_clf, x_train_flat, y_train_selected, x_test_flat, y_test, \"SVM\")\n",
        "\n",
        "    # Convert images to grayscale\n",
        "    x_train_gray = np.mean(x_train_selected, axis=3, keepdims=True) / 255.0\n",
        "    x_test_gray = np.mean(x_test, axis=3, keepdims=True) / 255.0\n",
        "\n",
        "    # Train and evaluate models for grayscale images\n",
        "    print(\"\\nGrayscale Images (LOOCV - 5000 training images):\")\n",
        "    print(\"==========================\")\n",
        "    evaluate_and_print_results(decision_tree_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), y_train_selected, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test, \"Decision Tree (Grayscale)\")\n",
        "    evaluate_and_print_results(random_forest_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), y_train_selected, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test, \"Random Forest (Grayscale)\")\n",
        "    evaluate_and_print_results(logistic_regression_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), y_train_selected, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test, \"Logistic Regression (Grayscale)\")\n",
        "    evaluate_and_print_results(svm_clf, x_train_gray.reshape(x_train_gray.shape[0], -1), y_train_selected, x_test_gray.reshape(x_test_gray.shape[0], -1), y_test, \"SVM (Grayscale)\")\n",
        "\n",
        "def evaluate_and_print_results(model, x_train, y_train, x_test, y_test, model_name):\n",
        "    accuracy, _, _, test_accuracy, test_classification_report, test_confusion_matrix = evaluate_model(model, x_train, y_train, x_test, y_test)\n",
        "    print(f\"{model_name} Mean LOOCV Accuracy:\", accuracy)\n",
        "    print(f\"{model_name} Test Accuracy:\", test_accuracy)\n",
        "    print(f\"{model_name} Test Classification Report:\\n\", test_classification_report)\n",
        "    print(f\"{model_name} Test Confusion Matrix:\\n\", test_confusion_matrix)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU8P6EjoJkSo",
        "outputId": "dbd001e7-053b-4cfc-cf4d-e174c4db8aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color Images (LOOCV - 5000 training images):\n",
            "==========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}